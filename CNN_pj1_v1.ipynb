{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:48.221865Z",
     "start_time": "2024-05-13T03:56:46.206542Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:48.228655Z",
     "start_time": "2024-05-13T03:56:48.222871Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "10857a89e93b5c42",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:52.963948Z",
     "start_time": "2024-05-13T03:56:48.228655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "# Đọc dữ liệu từ file CSV\n",
    "df = pd.read_csv('data.csv')\n",
    "    \n",
    "# Chọn các cột 'x1', 'x2', 'x3', 'x4', 'x5' làm đầu vào và 'y' làm đầu ra\n",
    "x_data = df[['x1', 'x2', 'x3', 'x4', 'x5']]\n",
    "y_data = df['y']\n",
    "\n",
    "# Khởi tạo danh sách để lưu trữ dữ liệu đầu vào dưới dạng tensors\n",
    "x_train = []\n",
    "\n",
    "# Lặp qua từng hàng trong x_data\n",
    "for index in range(len(x_data)):\n",
    "    # Lấy hàng thứ index từ DataFrame\n",
    "    row = x_data.iloc[index]\n",
    "    # Chuyển đổi từng giá trị trong hàng thành list\n",
    "    x_values = [ast.literal_eval(val) for val in row.values]\n",
    "    # Thêm tensor tương ứng vào danh sách x_train\n",
    "    x_train.append(torch.tensor(x_values, dtype=torch.float32))\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu ra thành tensor PyTorch\n",
    "y_train = torch.tensor(y_data.values, dtype=torch.long)\n",
    "\n",
    "# Tạo tensor từ danh sách các tensors đầu vào\n",
    "X_train = torch.stack(x_train)\n",
    "\n",
    "# In ra kích thước của tensors đầu vào và đầu ra\n",
    "print(\"x_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)"
   ],
   "id": "fbe6b0ddac4562c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: torch.Size([26846, 5, 10])\n",
      "y_train: torch.Size([26846])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:52.969943Z",
     "start_time": "2024-05-13T03:56:52.963948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "length = 10\n",
    "num_labels = 36\n",
    "num_sensors = 5"
   ],
   "id": "7e3a0a0842e859dd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:52.981483Z",
     "start_time": "2024-05-13T03:56:52.971480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tổng số mẫu\n",
    "total_samples = len(x_train)\n",
    "\n",
    "# Tính số lượng mẫu cho tập huấn luyện và tập kiểm tra\n",
    "train_size = int(0.8 * total_samples)  # 80% cho tập huấn luyện\n",
    "test_size = total_samples - train_size  # 20% cho tập kiểm tra\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "train_dataset, test_dataset = data.random_split(torch.utils.data.TensorDataset(X_train, y_train),\n",
    "                                                [train_size, test_size])\n",
    "\n",
    "# Khởi tạo DataLoader cho cả tập huấn luyện và tập kiểm tra\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "e041948e8ae029a7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNN model",
   "id": "d84c5de019f51c65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:52.991690Z",
     "start_time": "2024-05-13T03:56:52.981483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Định nghĩa mô hình CNN 1D\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(in_channels=512, out_channels=1024, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "        self.fc = nn.Linear(1024 * length, num_labels)    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for the fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "cee7591a551827c4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:52.997466Z",
     "start_time": "2024-05-13T03:56:52.991690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Huấn luyện mô hình\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.0001  # L2 regularization"
   ],
   "id": "cd97c8ca446af7b8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:53.022088Z",
     "start_time": "2024-05-13T03:56:52.997466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Khởi tạo mô hình\n",
    "input_size = num_sensors  # Số lượng cảm biến\n",
    "model = CNN1D(input_size=input_size, num_classes=num_labels).to(device)"
   ],
   "id": "ed3261ba78408305",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:53.864920Z",
     "start_time": "2024-05-13T03:56:53.022088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Khởi tạo optimizer và loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ],
   "id": "35b1c837e949584e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:53.872212Z",
     "start_time": "2024-05-13T03:56:53.864920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tạo label map từ chuỗi nhãn sang chỉ mục nguyên\n",
    "label_map = {}\n",
    "index = 0\n",
    "for i in range(1, 10):\n",
    "    for j in range(1, 5):\n",
    "        # Biểu diễn vị trí của mỗi ô trong lưới 9x4 dưới dạng chuỗi\n",
    "        label = f\"{i}{j}\"\n",
    "        # Ánh xạ chuỗi nhãn sang chỉ mục nguyên\n",
    "        label_map[label] = index\n",
    "        index += 1\n",
    "\n",
    "# In label map để kiểm tra\n",
    "print(label_map)\n",
    "\n",
    "\n",
    "# Hàm chuyển đổi chuỗi nhãn thành chỉ mục nguyên\n",
    "def label_to_index(labels):\n",
    "    # Chuyển đổi tensor labels về list giá trị của nó\n",
    "    labels_list = [str(label.item()) for label in labels]\n",
    "    # Sử dụng list giá trị để truy cập từ điển ánh xạ\n",
    "    return torch.tensor([label_map[label] for label in labels_list])\n",
    "\n",
    "# Tạo từ điển ánh xạ từ chỉ mục lớp sang nhãn\n",
    "index_to_label = {index: label for label, index in label_map.items()}\n",
    "\n",
    "# Hàm chuyển đổi chỉ mục thành nhãn\n",
    "def index_to_label_func(index):\n",
    "    return index_to_label[index]\n"
   ],
   "id": "26e77d8b2f8e2d67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': 0, '12': 1, '13': 2, '14': 3, '21': 4, '22': 5, '23': 6, '24': 7, '31': 8, '32': 9, '33': 10, '34': 11, '41': 12, '42': 13, '43': 14, '44': 15, '51': 16, '52': 17, '53': 18, '54': 19, '61': 20, '62': 21, '63': 22, '64': 23, '71': 24, '72': 25, '73': 26, '74': 27, '81': 28, '82': 29, '83': 30, '84': 31, '91': 32, '92': 33, '93': 34, '94': 35}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:55.153024Z",
     "start_time": "2024-05-13T03:56:53.872212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_losses=[]\n",
    "# Huấn luyện mô hình\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Chuyển sang chế độ huấn luyện\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels_str in train_loader:\n",
    "        inputs, labels_str = inputs.to(device), labels_str\n",
    "\n",
    "        # Chuyển đổi nhãn thành chỉ mục nguyên\n",
    "        labels = label_to_index(labels_str).to(device)\n",
    "\n",
    "        # Feedforward\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Tính loss và backward\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Lưu trữ loss cho epoch hiện tại\n",
    "    train_losses.append(running_loss / (num_samples / batch_size))\n",
    "\n",
    "    if (epoch+1)%10==0:\n",
    "      # Lưu trạng thái của mô hình vào một tệp tin\n",
    "      torch.save(model.state_dict(), model_file_path)\n",
    "      print(f'Da luu model: {model_file_path}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "id": "4e5d3e959dbd56f4",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x5120 and 10240x36)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m labels \u001B[38;5;241m=\u001B[39m label_to_index(labels_str)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Feedforward\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Tính loss và backward\u001B[39;00m\n\u001B[0;32m     16\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 26\u001B[0m, in \u001B[0;36mCNN1D.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mview(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Flatten the tensor for the fully connected layer\u001B[39;00m\n\u001B[0;32m     25\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(x)\n\u001B[1;32m---> 26\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(x)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (32x5120 and 10240x36)"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:56:55.153024Z",
     "start_time": "2024-05-13T03:56:55.153024Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "238cfff2f3862806",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
